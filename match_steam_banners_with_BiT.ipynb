{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "match_steam_banners_with_BiT.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqMf9Tz3LZ_k"
      },
      "source": [
        "%pip install --quiet gamedatacrunch webdataset mediapy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkaODmJSL5Ka"
      },
      "source": [
        "%cd /content\n",
        "\n",
        "!wget https://github.com/woctezuma/steam-BiT/releases/download/v0.1-data/20210928_gamedatacrunch.json\n",
        "!wget https://github.com/woctezuma/steam-BiT/releases/download/v0.1-data/steam_webdataset.tar\n",
        "\n",
        "!tar xf steam_webdataset.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyuCb6pgMOGr"
      },
      "source": [
        "import gamedatacrunch as gdc\n",
        "\n",
        "app_ids = gdc.load_app_ids('20210928_gamedatacrunch.json')\n",
        "app_ids = sorted(app_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEaf0sNKOM6L"
      },
      "source": [
        "# Reference: https://github.com/rom1504/img2dataset/issues/32\n",
        "\n",
        "num_datasets = 7\n",
        "data_locations = [ f\"images/{i:05d}.tar\" for i in range(num_datasets) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryh9OohFRWXD"
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "normalize = transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406],\n",
        "    std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "\n",
        "preproc = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTJ3Jx8mM_XQ"
      },
      "source": [
        "import webdataset as wds\n",
        "from itertools import islice\n",
        "import mediapy as media\n",
        "import numpy as np\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "# Reference: https://webdataset.github.io/webdataset/gettingstarted/\n",
        "dataset = wds.WebDataset(data_locations).decode('pil').to_tuple(\"jpg;png\", \"json\").map_tuple(preproc, identity)\n",
        "\n",
        "for image, data in islice(dataset, 42, 43):\n",
        "    print(image.shape, image.dtype, type(data))\n",
        "    print(data['url'])\n",
        "    media.show_image(to_pil_image(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S_vSM12fOoJ"
      },
      "source": [
        "## Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpLE3Syce_rA"
      },
      "source": [
        "from functools import partial\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfaN0tKbfZPC"
      },
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsbO8k4ZfaPJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision as tv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XfC7OtSfbF-"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBaqzATofb7b"
      },
      "source": [
        "import requests\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co9hGih-feJY"
      },
      "source": [
        "def get_weights(bit_variant):\n",
        "  response = requests.get(f'https://storage.googleapis.com/bit_models/{bit_variant}.npz')\n",
        "  response.raise_for_status()\n",
        "  return np.load(io.BytesIO(response.content))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBPnVizDfpnz"
      },
      "source": [
        "class StdConv2d(nn.Conv2d):\n",
        "  def forward(self, x):\n",
        "    w = self.weight\n",
        "    v, m = torch.var_mean(w, dim=[1, 2, 3], keepdim=True, unbiased=False)\n",
        "    w = (w - m) / torch.sqrt(v + 1e-10)\n",
        "    return F.conv2d(x, w, self.bias, self.stride, self.padding, self.dilation, self.groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYnMZ_8Bft1i"
      },
      "source": [
        "def conv3x3(cin, cout, stride=1, groups=1, bias=False):\n",
        "  return StdConv2d(cin, cout, kernel_size=3, stride=stride, padding=1, bias=bias, groups=groups)\n",
        "\n",
        "def conv1x1(cin, cout, stride=1, bias=False):\n",
        "  return StdConv2d(cin, cout, kernel_size=1, stride=stride, padding=0, bias=bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAC5h5jvfu2O"
      },
      "source": [
        "def tf2th(conv_weights):\n",
        "  \"\"\"Possibly convert HWIO to OIHW\"\"\"\n",
        "  if conv_weights.ndim == 4:\n",
        "    conv_weights = np.transpose(conv_weights, [3, 2, 0, 1])\n",
        "  return torch.from_numpy(conv_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNq34tmsqgXG"
      },
      "source": [
        "class PreActBottleneck(nn.Module):\n",
        "  \"\"\"\n",
        "  Follows the implementation of \"Identity Mappings in Deep Residual Networks\" here:\n",
        "  https://github.com/KaimingHe/resnet-1k-layers/blob/master/resnet-pre-act.lua\n",
        "\n",
        "  Except it puts the stride on 3x3 conv when available.\n",
        "  \"\"\"\n",
        "  def __init__(self, cin, cout=None, cmid=None, stride=1):\n",
        "    super().__init__()\n",
        "    cout = cout or cin\n",
        "    cmid = cmid or cout//4\n",
        "\n",
        "    self.gn1 = nn.GroupNorm(32, cin)\n",
        "    self.conv1 = conv1x1(cin, cmid)\n",
        "    self.gn2 = nn.GroupNorm(32, cmid)\n",
        "    self.conv2 = conv3x3(cmid, cmid, stride)  # Original ResNetv2 has it on conv1!!\n",
        "    self.gn3 = nn.GroupNorm(32, cmid)\n",
        "    self.conv3 = conv1x1(cmid, cout)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    if (stride != 1 or cin != cout):\n",
        "      # Projection also with pre-activation according to paper.\n",
        "      self.downsample = conv1x1(cin, cout, stride)\n",
        "\n",
        "  def forward(self, x):\n",
        "      # Conv'ed branch\n",
        "      out = self.relu(self.gn1(x))\n",
        "\n",
        "      # Residual branch\n",
        "      residual = x\n",
        "      if hasattr(self, 'downsample'):\n",
        "          residual = self.downsample(out)\n",
        "\n",
        "      # The first block has already applied pre-act before splitting, see Appendix.\n",
        "      out = self.conv1(out)\n",
        "      out = self.conv2(self.relu(self.gn2(out)))\n",
        "      out = self.conv3(self.relu(self.gn3(out)))\n",
        "\n",
        "      return out + residual\n",
        "\n",
        "  def load_from(self, weights, prefix=''):\n",
        "    with torch.no_grad():\n",
        "      self.conv1.weight.copy_(tf2th(weights[prefix + 'a/standardized_conv2d/kernel']))\n",
        "      self.conv2.weight.copy_(tf2th(weights[prefix + 'b/standardized_conv2d/kernel']))\n",
        "      self.conv3.weight.copy_(tf2th(weights[prefix + 'c/standardized_conv2d/kernel']))\n",
        "      self.gn1.weight.copy_(tf2th(weights[prefix + 'a/group_norm/gamma']))\n",
        "      self.gn2.weight.copy_(tf2th(weights[prefix + 'b/group_norm/gamma']))\n",
        "      self.gn3.weight.copy_(tf2th(weights[prefix + 'c/group_norm/gamma']))\n",
        "      self.gn1.bias.copy_(tf2th(weights[prefix + 'a/group_norm/beta']))\n",
        "      self.gn2.bias.copy_(tf2th(weights[prefix + 'b/group_norm/beta']))\n",
        "      self.gn3.bias.copy_(tf2th(weights[prefix + 'c/group_norm/beta']))\n",
        "      if hasattr(self, 'downsample'):\n",
        "        self.downsample.weight.copy_(tf2th(weights[prefix + 'a/proj/standardized_conv2d/kernel']))\n",
        "    return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-VHMnmvfz4W"
      },
      "source": [
        "class ResNetV2(nn.Module):\n",
        "  BLOCK_UNITS = {\n",
        "      'r50': [3, 4, 6, 3],\n",
        "      'r101': [3, 4, 23, 3],\n",
        "      'r152': [3, 8, 36, 3],\n",
        "  }\n",
        "\n",
        "  def __init__(self, block_units, width_factor, head_size=21843, zero_head=False):\n",
        "    super().__init__()\n",
        "    wf = width_factor  # shortcut 'cause we'll use it a lot.\n",
        "\n",
        "    self.root = nn.Sequential(OrderedDict([\n",
        "        ('conv', StdConv2d(3, 64*wf, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "        ('padp', nn.ConstantPad2d(1, 0)),\n",
        "        ('pool', nn.MaxPool2d(kernel_size=3, stride=2, padding=0)),\n",
        "        # The following is subtly not the same!\n",
        "        #('pool', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "    ]))\n",
        "\n",
        "    self.body = nn.Sequential(OrderedDict([\n",
        "        ('block1', nn.Sequential(OrderedDict(\n",
        "            [('unit01', PreActBottleneck(cin= 64*wf, cout=256*wf, cmid=64*wf))] +\n",
        "            [(f'unit{i:02d}', PreActBottleneck(cin=256*wf, cout=256*wf, cmid=64*wf)) for i in range(2, block_units[0] + 1)],\n",
        "        ))),\n",
        "        ('block2', nn.Sequential(OrderedDict(\n",
        "            [('unit01', PreActBottleneck(cin=256*wf, cout=512*wf, cmid=128*wf, stride=2))] +\n",
        "            [(f'unit{i:02d}', PreActBottleneck(cin=512*wf, cout=512*wf, cmid=128*wf)) for i in range(2, block_units[1] + 1)],\n",
        "        ))),\n",
        "        ('block3', nn.Sequential(OrderedDict(\n",
        "            [('unit01', PreActBottleneck(cin= 512*wf, cout=1024*wf, cmid=256*wf, stride=2))] +\n",
        "            [(f'unit{i:02d}', PreActBottleneck(cin=1024*wf, cout=1024*wf, cmid=256*wf)) for i in range(2, block_units[2] + 1)],\n",
        "        ))),\n",
        "        ('block4', nn.Sequential(OrderedDict(\n",
        "            [('unit01', PreActBottleneck(cin=1024*wf, cout=2048*wf, cmid=512*wf, stride=2))] +\n",
        "            [(f'unit{i:02d}', PreActBottleneck(cin=2048*wf, cout=2048*wf, cmid=512*wf)) for i in range(2, block_units[3] + 1)],\n",
        "        ))),\n",
        "    ]))\n",
        "\n",
        "    self.zero_head = zero_head\n",
        "    self.head = nn.Sequential(OrderedDict([\n",
        "        ('gn', nn.GroupNorm(32, 2048*wf)),\n",
        "        ('relu', nn.ReLU(inplace=True)),\n",
        "        ('avg', nn.AdaptiveAvgPool2d(output_size=1)),\n",
        "        ('conv', nn.Conv2d(2048*wf, head_size, kernel_size=1, bias=True)),\n",
        "    ]))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.head(self.body(self.root(x)))\n",
        "    assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left.\n",
        "    return x[...,0,0]\n",
        "\n",
        "  def load_from(self, weights, prefix='resnet/'):\n",
        "    with torch.no_grad():\n",
        "      self.root.conv.weight.copy_(tf2th(weights[f'{prefix}root_block/standardized_conv2d/kernel']))\n",
        "      self.head.gn.weight.copy_(tf2th(weights[f'{prefix}group_norm/gamma']))\n",
        "      self.head.gn.bias.copy_(tf2th(weights[f'{prefix}group_norm/beta']))\n",
        "      if self.zero_head:\n",
        "        nn.init.zeros_(self.head.conv.weight)\n",
        "        nn.init.zeros_(self.head.conv.bias)\n",
        "      else:\n",
        "        self.head.conv.weight.copy_(tf2th(weights[f'{prefix}head/conv2d/kernel']))\n",
        "        self.head.conv.bias.copy_(tf2th(weights[f'{prefix}head/conv2d/bias']))\n",
        "\n",
        "      for bname, block in self.body.named_children():\n",
        "        for uname, unit in block.named_children():\n",
        "          unit.load_from(weights, prefix=f'{prefix}{bname}/{uname}/')\n",
        "    return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDgrCT4AgWHd"
      },
      "source": [
        "weights = get_weights('distill/R50x1_224')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyDE_--zf5ZJ"
      },
      "source": [
        "model = ResNetV2(ResNetV2.BLOCK_UNITS['r50'], width_factor=1, head_size=1000)  # NOTE: No new head.\n",
        "model.load_from(weights)\n",
        "model.to(device);\n",
        "\n",
        "# Remove the classification head\n",
        "model.head.conv = torch.nn.Identity()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwEcsaJk_1r9"
      },
      "source": [
        "# Batch of 1 image with unsqueeze(0)\n",
        "# Reference: https://stackoverflow.com/q/57237381/376454\n",
        "features = model(image.to(device).unsqueeze(0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}